# LLM Configuration
OPENAI_API_KEY=your_openai_api_key_here
# OLLAMA_BASE_URL=http://localhost:11434  # Para usar Ollama local

# Vector Database
CHROMADB_URL=http://localhost:8000
# SUPABASE_URL=your_supabase_url
# SUPABASE_KEY=your_supabase_key

# Application
NODE_ENV=development
PORT=3000

# Optional: Logging
LOG_LEVEL=info
